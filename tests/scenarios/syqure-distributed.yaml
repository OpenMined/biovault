setup:
  server:
    - "SYFTBOX_HOTLINK=${BV_SYFTBOX_HOTLINK-1} SYFTBOX_HOTLINK_SOCKET_ONLY=1 SYFTBOX_HOTLINK_TCP_PROXY=${BV_SYQURE_TCP_PROXY-1} SYFTBOX_HOTLINK_TCP_PROXY_ADDR=${BV_SYFTBOX_HOTLINK_TCP_PROXY_ADDR-127.0.0.1} SYFTBOX_HOTLINK_QUIC=${BV_SYFTBOX_HOTLINK_QUIC-1} SYFTBOX_HOTLINK_P2P_ONLY=${BV_SYFTBOX_HOTLINK_P2P_ONLY-${BV_SYFTBOX_HOTLINK_QUIC_ONLY-0}} SYFTBOX_HOTLINK_QUIC_ONLY=${BV_SYFTBOX_HOTLINK_QUIC_ONLY-${BV_SYFTBOX_HOTLINK_P2P_ONLY-0}} BV_SYQURE_TCP_PROXY=${BV_SYQURE_TCP_PROXY-1} ./tests/scripts/devstack.sh --reset --clients client1@sandbox.local,client2@sandbox.local,aggregator@sandbox.local"

steps:
  - name: Initialize BioVault for client1
    datasite: client1@sandbox.local
    run: |
      {{workspace}}/cli/target/release/bv init client1@sandbox.local --quiet

  - name: Initialize BioVault for client2
    datasite: client2@sandbox.local
    run: |
      {{workspace}}/cli/target/release/bv init client2@sandbox.local --quiet

  - name: Initialize BioVault for aggregator
    datasite: aggregator@sandbox.local
    run: |
      {{workspace}}/cli/target/release/bv init aggregator@sandbox.local --quiet

  # Smoke test: verify SyftBox sync is working
  - name: Wait for client1 public key to sync to client2
    datasite: client2@sandbox.local
    wait_for: datasites/client1@sandbox.local/public/crypto/did.json
    timeout: 30

  - name: Wait for client2 public key to sync to client1
    datasite: client1@sandbox.local
    wait_for: datasites/client2@sandbox.local/public/crypto/did.json
    timeout: 30

  - name: Wait for aggregator public key to sync to client1
    datasite: client1@sandbox.local
    wait_for: datasites/aggregator@sandbox.local/public/crypto/did.json
    timeout: 30

  - name: Smoke test sync complete
    run: |
      echo "SyftBox sync smoke test passed - public keys are syncing"

  - name: Select Syqure aggregation mode
    run: |
      MODE="${BV_SYQURE_AGG_MODE:-smpc}"
      RAW_TRANSPORT="${BV_SYQURE_TRANSPORT:-hotlink}"
      case "${RAW_TRANSPORT}" in
        hotlink|webrtc|"")
          TRANSPORT="hotlink"
          ;;
        file)
          TRANSPORT="file"
          ;;
        *)
          echo "Unknown BV_SYQURE_TRANSPORT: ${RAW_TRANSPORT} (expected hotlink|file)" >&2
          exit 1
          ;;
      esac
      MODULE_YAML="{{workspace}}/tests/scenarios/syqure-flow/modules/secure-aggregate/module.yaml"
      case "$MODE" in
        he) ENTRY="he_aggregate.codon" ;;
        smpc|"") ENTRY="smpc_aggregate.codon" ;;
        *)
          echo "Unknown BV_SYQURE_AGG_MODE: $MODE (expected smpc|he)" >&2
          exit 1
          ;;
      esac
      python3 -c "import pathlib,re; path = pathlib.Path(\"${MODULE_YAML}\"); text = path.read_text(); text = text.replace(\"entrypoint: smpc_aggregate.codon\", f\"entrypoint: ${ENTRY}\"); text = text.replace(\"entrypoint: he_aggregate.codon\", f\"entrypoint: ${ENTRY}\"); text = re.sub(r\"transport: .*\", f\"transport: ${TRANSPORT}\", text); path.write_text(text)"
      echo "Syqure aggregation mode: ${MODE} (entrypoint: ${ENTRY}) transport: ${TRANSPORT}"

  # Permissions are created declaratively by the flow.yaml init_permissions step
  # run_id is auto-generated by the scenario runner for distributed flow coordination
  # BV_SYQURE_USE_DOCKER is inherited from environment (set by --docker flag)
  # SyftBox devstack handles file sync between parties
  - parallel:
      - name: client1-flow
        datasite: client1@sandbox.local
        run: |
          cd {{workspace}}
          TIMEFORMAT='flow_time:%3R'
          time BIOVAULT_FLOW_VERBOSE=1 BIOVAULT_FLOW_RUN_ID={{run_id}} \
            BV_SYQURE_USE_DOCKER=${BV_SYQURE_USE_DOCKER:-} \
            {{workspace}}/cli/target/release/bv run tests/scenarios/syqure-flow/flow.yaml

      - name: client2-flow
        datasite: client2@sandbox.local
        run: |
          cd {{workspace}}
          TIMEFORMAT='flow_time:%3R'
          time BIOVAULT_FLOW_VERBOSE=1 BIOVAULT_FLOW_RUN_ID={{run_id}} \
            BV_SYQURE_USE_DOCKER=${BV_SYQURE_USE_DOCKER:-} \
            {{workspace}}/cli/target/release/bv run tests/scenarios/syqure-flow/flow.yaml

      - name: aggregator-flow
        datasite: aggregator@sandbox.local
        run: |
          cd {{workspace}}
          TIMEFORMAT='flow_time:%3R'
          time BIOVAULT_FLOW_VERBOSE=1 BIOVAULT_FLOW_RUN_ID={{run_id}} \
            BV_SYQURE_USE_DOCKER=${BV_SYQURE_USE_DOCKER:-} \
            {{workspace}}/cli/target/release/bv run tests/scenarios/syqure-flow/flow.yaml
    timeout: 420

  - name: Assert hotlink p2p-only telemetry (no websocket fallback)
    shell: bash
    run: |
      P2P_ONLY="${BV_SYFTBOX_HOTLINK_P2P_ONLY:-${BV_SYFTBOX_HOTLINK_QUIC_ONLY:-0}}"
      if [[ "${P2P_ONLY}" != "1" ]]; then
        echo "P2P-only assertion skipped (BV_SYFTBOX_HOTLINK_P2P_ONLY/BV_SYFTBOX_HOTLINK_QUIC_ONLY not set)"
        exit 0
      fi
      python3 - <<'PY'
      import json
      from pathlib import Path

      root = Path("{{workspace}}/sandbox")
      peers = ["client1@sandbox.local", "client2@sandbox.local", "aggregator@sandbox.local"]
      total_ws_packets = 0
      total_ws_fallbacks = 0
      total_p2p_packets = 0
      total_webrtc_connected = 0
      missing = []

      for peer in peers:
          candidates = [
              root / peer / "datasites" / peer / ".syftbox" / "hotlink_telemetry.json",
              root / peer / ".syftbox" / "hotlink_telemetry.json",
          ]
          path = next((p for p in candidates if p.exists()), None)
          if path is None:
              missing.append(peer)
              continue
          data = json.loads(path.read_text())
          ws_packets = int(data.get("tx_ws_packets", 0))
          ws_fallbacks = int(data.get("ws_fallbacks", 0))
          p2p_packets = int(data.get("tx_p2p_packets", data.get("tx_quic_packets", 0) or 0))
          connected = int(data.get("webrtc_connected", 0))
          mode = data.get("mode", "unknown")
          print(
              f"{peer}: mode={mode} tx_p2p={p2p_packets} tx_ws={ws_packets} ws_fb={ws_fallbacks} webrtc_connected={connected}"
          )
          total_ws_packets += ws_packets
          total_ws_fallbacks += ws_fallbacks
          total_p2p_packets += p2p_packets
          total_webrtc_connected += connected

      if missing:
          raise SystemExit(f"Missing hotlink telemetry for peers: {', '.join(missing)}")
      if total_ws_packets > 0 or total_ws_fallbacks > 0:
          raise SystemExit(
              f"P2P-only violation: ws_tx={total_ws_packets} ws_fallbacks={total_ws_fallbacks}"
          )
      if total_p2p_packets == 0 or total_webrtc_connected == 0:
          raise SystemExit(
              f"P2P-only violation: no active webrtc dataplane (tx_p2p={total_p2p_packets}, webrtc_connected={total_webrtc_connected})"
          )
      print("✓ P2P-only telemetry assertion passed")
      PY

  - name: Verify flow completion
    datasite: aggregator@sandbox.local
    run: |
      echo "=== Checking progress files for run {{run_id}} ==="

      # Structure: datasites/{ds}/shared/flows/syqure-flow/{run_id}/progress/progress.json
      # Each datasite writes to their own shared folder
      for ds in client1@sandbox.local client2@sandbox.local aggregator@sandbox.local; do
        PROGRESS_DIR="datasites/${ds}/shared/flows/syqure-flow/{{run_id}}/progress"
        PROGRESS_JSON="${PROGRESS_DIR}/progress.json"
        PROGRESS_LOG="${PROGRESS_DIR}/progress.log"

        echo ""
        echo "=== Progress for ${ds} ==="
        if [[ -f "$PROGRESS_JSON" ]]; then
          echo "progress.json:"
          cat "$PROGRESS_JSON"
        else
          echo "No progress.json found at ${PROGRESS_JSON}"
        fi

        if [[ -f "$PROGRESS_LOG" ]]; then
          echo ""
          echo "progress.log:"
          cat "$PROGRESS_LOG"
        fi
      done

      echo ""
      echo "=== DISTRIBUTED FLOW TEST COMPLETE ==="

  - name: Verify aggregation result
    shell: bash
    run: |
      if [[ "${BV_SYQURE_HE:-0}" = "1" ]]; then
        RESULT_LABEL="HE"
      else
        RESULT_LABEL="MPC"
      fi
      echo "=== Verifying ${RESULT_LABEL} aggregation result ==="

      # Read inputs
      CLIENT1_COUNTS=$(cat {{workspace}}/results/flows/syqure-flow/align_counts/client1_sandbox_local/counts_array.json | tr -d '[:space:]')
      CLIENT2_COUNTS=$(cat {{workspace}}/results/flows/syqure-flow/align_counts/client2_sandbox_local/counts_array.json | tr -d '[:space:]')

      # Read results from CLIENTS (not aggregator - aggregator is trusted dealer with no revealed values)
      RESULT_CLIENT1=$(cat {{workspace}}/results/flows/syqure-flow/secure_aggregate/client1_sandbox_local/aggregated_counts.json | tr -d '[:space:]')
      RESULT_CLIENT2=$(cat {{workspace}}/results/flows/syqure-flow/secure_aggregate/client2_sandbox_local/aggregated_counts.json | tr -d '[:space:]')
      RESULT_AGG=$(cat {{workspace}}/results/flows/syqure-flow/secure_aggregate/aggregator_sandbox_local/aggregated_counts.json | tr -d '[:space:]')

      echo "Client1 input:  $CLIENT1_COUNTS"
      echo "Client2 input:  $CLIENT2_COUNTS"
      echo "Result client1: $RESULT_CLIENT1"
      echo "Result client2: $RESULT_CLIENT2"
      echo "Result agg:     $RESULT_AGG (expected zeros - trusted dealer)"

      # Parse arrays and compute expected sum using Python
      EXPECTED=$(python3 -c "
      import json
      c1 = json.loads('$CLIENT1_COUNTS')
      c2 = json.loads('$CLIENT2_COUNTS')
      expected = [a + b for a, b in zip(c1, c2)]
      print(json.dumps(expected, separators=(',', ':')))
      ")

      echo "Expected:       $EXPECTED"

      # Both clients should have the same correct result
      if [ "$RESULT_CLIENT1" = "$EXPECTED" ] && [ "$RESULT_CLIENT2" = "$EXPECTED" ]; then
        echo "✓ ${RESULT_LABEL} aggregation result is correct!"
      else
        echo "✗ ERROR: ${RESULT_LABEL} result does not match expected sum"
        echo "  Client1 got: $RESULT_CLIENT1"
        echo "  Client2 got: $RESULT_CLIENT2"
        exit 1
      fi
